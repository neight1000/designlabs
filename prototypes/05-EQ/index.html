<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Visual EQ</title>
  <style>
    /* Minimal black-and-white styling */
    html, body {
      margin: 0;
      padding: 0;
      background: #000;
      color: #fff;
      font-family: sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      height: 100vh;
      box-sizing: border-box;
    }
    #controls {
      margin: 10px;
      display: flex;
      gap: 10px;
    }
    select, button {
      background: #000;
      color: #fff;
      border: 1px solid #fff;
      padding: 5px 10px;
      font-size: 1rem;
    }
    canvas {
      display: block;
      width: 90vw;
      height: 200px;
      touch-action: none; /* improve mobile/touch compatibility */
    }
  </style>
</head>
<body>
  <div id="controls">
    <select id="deviceSelect"></select>
    <button id="startBtn">Start</button>
  </div>
  <canvas id="vis"></canvas>

  <script>
    // Elements
    const deviceSelect = document.getElementById('deviceSelect');
    const startBtn = document.getElementById('startBtn');
    const canvas = document.getElementById('vis');
    const ctx = canvas.getContext('2d');

    let audioContext, analyser, dataArray;

    // Resize canvas to match CSS dimensions
    function resizeCanvas() {
      canvas.width = window.innerWidth * 0.9;
      canvas.height = 200;
    }
    window.addEventListener('resize', resizeCanvas);
    resizeCanvas();

    // Enumerate audio input devices
    async function populateDevices() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const inputs = devices.filter(d => d.kind === 'audioinput');
      inputs.forEach((d, i) => {
        const opt = document.createElement('option');
        opt.value = d.deviceId;
        opt.textContent = d.label || `Microphone ${i + 1}`;
        deviceSelect.appendChild(opt);
      });
    }

    // Start processing
    async function startEQ() {
      if (audioContext) return; // already started

      // get permission & open stream
      const deviceId = deviceSelect.value;
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: { deviceId: deviceId ? { exact: deviceId } : undefined }
      });

      // Web Audio setup
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 512;
      const bufferLength = analyser.frequencyBinCount;
      dataArray = new Uint8Array(bufferLength);

      // connect nodes: source → analyser → destination
      source.connect(analyser);
      analyser.connect(audioContext.destination);

      // begin draw loop
      draw();
    }

    // Draw real-time frequency bars
    function draw() {
      requestAnimationFrame(draw);
      analyser.getByteFrequencyData(dataArray);

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      const barWidth = canvas.width / dataArray.length;

      for (let i = 0; i < dataArray.length; i++) {
        const barHeight = (dataArray[i] / 255) * canvas.height;
        const x = i * barWidth;
        ctx.fillStyle = '#fff';
        ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
      }
    }

    // Event listeners
    startBtn.addEventListener('click', startEQ);

    // On load
    populateDevices();
  </script>
</body>
</html>


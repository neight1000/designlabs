<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Visual EQ</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      background: #000;
      color: #fff;
      font-family: sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      height: 100vh;
      box-sizing: border-box;
    }
    #controls {
      margin: 10px;
      display: flex;
      gap: 10px;
      z-index: 10;
    }
    select, button {
      background: #000;
      color: #fff;
      border: 1px solid #fff;
      padding: 5px 10px;
      font-size: 1rem;
    }
    canvas {
      display: block;
      width: 90vw;
      height: 200px;
      touch-action: none;
      background: #000;
    }
    /* When fullscreen, make canvas fill everything */
    :fullscreen canvas {
      width: 100vw !important;
      height: 100vh !important;
    }
  </style>
</head>
<body>
  <div id="controls">
    <select id="deviceSelect"></select>
    <button id="startBtn">Start</button>
    <button id="fsBtn">Fullscreen</button>
  </div>
  <canvas id="vis"></canvas>

  <script>
    const deviceSelect = document.getElementById('deviceSelect');
    const startBtn     = document.getElementById('startBtn');
    const fsBtn        = document.getElementById('fsBtn');
    const canvas       = document.getElementById('vis');
    const ctx          = canvas.getContext('2d');
    let audioContext, analyser, dataArray;

    function resizeCanvas() {
      // match CSS dimensions
      const style = getComputedStyle(canvas);
      canvas.width  = parseFloat(style.width);
      canvas.height = parseFloat(style.height);
    }

    window.addEventListener('resize', resizeCanvas);
    document.addEventListener('fullscreenchange', resizeCanvas);
    resizeCanvas();

    async function populateDevices() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      devices.filter(d => d.kind === 'audioinput')
             .forEach((d,i) => {
        const opt = document.createElement('option');
        opt.value = d.deviceId;
        opt.textContent = d.label || `Mic ${i+1}`;
        deviceSelect.appendChild(opt);
      });
    }

    async function startEQ() {
      if (audioContext) return;
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: { deviceId: deviceSelect.value ? { exact: deviceSelect.value } : undefined }
      });
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 512;
      dataArray = new Uint8Array(analyser.frequencyBinCount);
      source.connect(analyser);
      draw();
    }

    function draw() {
      requestAnimationFrame(draw);
      analyser.getByteFrequencyData(dataArray);
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      ctx.beginPath();
      const slice = canvas.width / dataArray.length;
      let x = 0;
      for (let i = 0; i < dataArray.length; i++) {
        const v = dataArray[i] / 255;
        const y = canvas.height - (v * canvas.height);
        if (i === 0) {
          ctx.moveTo(x, y);
        } else {
          ctx.lineTo(x, y);
        }
        x += slice;
      }
      ctx.lineWidth = 2;
      ctx.strokeStyle = '#fff';
      ctx.stroke();
    }

    startBtn.addEventListener('click', startEQ);

    fsBtn.addEventListener('click', () => {
      if (!document.fullscreenElement) {
        document.documentElement.requestFullscreen();
      } else {
        document.exitFullscreen();
      }
    });

    populateDevices();
  </script>
</body>
</html>
